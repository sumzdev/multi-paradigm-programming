# 백엔드 비동기 프로그래밍

백엔드 환경에서는 비동기적 상황이 빈번히 발생하며 자원을 효율적으로 활용하거나 병렬성을 통해 작업 시간을 단축하는 것이 중요합니다. 그러한 문제를 해결하기 위한 실용적인 사례로 결제 내역 동기화 스케줄러를 만들어보겠습니다.

## (1) 커머스 플랫폼의 결제 프로세스 문제

### 일반적인 결제 과정 흐름

1. 고객이 결제 버튼 누름
2. 결제 대행사(PG사)의 결제 창이 열리고 결제 시도
3. 결제 성공시 결과가 PG사로부터 우리 커머스 플랫폼으로 전달됨
4. 커머스 플랫폼은 전달받은 결제 결과를 토대로 주문 데이터를 생성하거나 결제 완료 상태로 갱신

이 과정에서 네트워크 장애, 브라우저 종료, 서버 장애 등 다양한 이유 때문에 결제 성공 알림이 커머스 플랫폼에 정상적으로 전달되지 못하는 상황이 발생할 수 있습니다. 이로 인해 고객의 결제가 완료되었음에도 불구하고 주문이 생성되지 않는 데이터 불일치 문제가 생깁니다.
이를 해결하려면 주기적으로 ‘PG사의 결제 데이터를 조회하여 우리 커머스 플랫폼의 데이터와 대조하는 작업’이 필요합니다. 이 작업에는 누락된 주문을 확인하고 자동으로 처리하거나 누락된 결제를 환불하는 프로세스가 포함됩니다. 이러한 **동기화 작업**은 데이터 불일치를 해결하고 고객의 결제 및 주문 문제를 예방하며 전반적인 고객 경험을 개선하는 데 중요한 역할을 합니다.

## (2) 결제 내역 동기화 스케줄러 만들기

결제 상태 동기화로 누락된 상황을 처 리하는 반복 실행 스케줄러를 구현합니다. 결제 데이터를 주기적으로 조회하고 누락된 데이터를 확인하며 자동으로 환불 프로세스를 실행합니다.

### 결제 서비스(PG사) SDK — 결제 데이터 조회와 결제 취소 기능 제공

```tsx
import { fx, map, range } from '@fxts/core';

// delay 함수 : 비동기 작업을 시뮬레이션하기 위해 사용됩니다.
function delay<T>(time: number): Promise<undefined>;
function delay<T>(time: number, value: T): Promise<T>;
function delay<T>(time: number, value?: T): Promise<T | undefined> {
  return new Promise(resolve => {
    setTimeout(() => resolve(value), time);
  });
}

type Payment = {
  // pg_uid는 결제 서비스(PG사)측의 고유한 결제 ID
  pg_uid: string;
  // store_order_id는 우리 커머스 플랫폼의 주문 데이터베이스에 기록된 주문번호
  store_order_id: number;
  amount: number;
};

const pgDataPaymentsPages: Payment[][] = [
  [
    { pg_uid: 'PG11', store_order_id: 1, amount: 15000 },
    { pg_uid: 'PG12', store_order_id: 2, amount: 25000 },
    { pg_uid: 'PG13', store_order_id: 3, amount: 10000 },
  ],
  [
    { pg_uid: 'PG14', store_order_id: 4, amount: 25000 },
    { pg_uid: 'PG15', store_order_id: 5, amount: 45000 },
    { pg_uid: 'PG16', store_order_id: 6, amount: 15000 },
  ],
  [
    { pg_uid: 'PG17', store_order_id: 7, amount: 20000 },
    { pg_uid: 'PG18', store_order_id: 8, amount: 30000 },
  ],
];

// Payment Gateway API
const PgApi = {
  /**
   * 특정 시간 동안의 모든 결제 내역 조회(편의상 시간 범위 지정 인자 생략)
   * - page 조회할 페이지 번호를 받아 해당 페이지의 결제 데이터를 반환함
   * - 결과는 여러 페이지일 수도 있음
   * - 각 페이지에는 최대 3개의 결제 항목이 포함되며, 요청한 페이지에 데이터가 없는 경우 빈 배열 반환
   */
  async getPayments(page: number) {
    console.log(`Payments request: https://pg.com/payments?page=${page}`);
    await delay(500);

    const payments = pgDataPaymentsPages[page - 1] ?? [];
    console.log(
      `${payments.length}: ${payments.map(p => p.pg_uid).join(', ') || '-'}`,
    );

    return payments;
  },

  /**
   * 결제 취소 및 환불
   * - pg_uid 취소할 결제 ID
   * - 결제 ID를 받아 PG사에 기록된 결제를 취소하고 환불한다.
   */
  async cancelPayment(pg_uid: string) {
    console.log(`Cancellation request: ${pg_uid}`);
    await delay(300);
    return {
      code: 200,
      message: `${pg_uid}: Cancellation and refund completed`,
      pg_uid,
    };
  },
};
```

### 가상 StoreDB — 우리 커머스 플랫폼의 주문 데이터를 조회할 수 있는 가상 StoreDB

주문 ID를 기반으로 데이터를 조회하고 조건에 따라 필요한 주문 정보만 반환하는 역할을 수행한다.

```tsx
type Order = {
  id: number;
  amount: number;
  is_paid: boolean;
};

const StoreDB = {
  // 결제 완료된 주문 데이터를 필터링하여 반환하는 데이터베이스 역할을 시뮬레이션한다.
  // 전달받은 ids를 기반으로 데이터베이스에서 주문을 조ㅗ히하며 결제가 완료된 주문만 결과로 반환
  async getOrders(ids: number[]): Promise<Order[]> {
    console.log(`SELECT * FROM orders WHERE IN (${ids}) AND is_paid = true;`);

    // delay(100)을 사용하여 비동기 작업을 시뮬레이션한다.
    await delay(100);
    return [
      { id: 1, amount: 15000, is_paid: true },
      { id: 3, amount: 10000, is_paid: true },
      { id: 5, amount: 45000, is_paid: true },
      { id: 7, amount: 20000, is_paid: true },
      { id: 8, amount: 30000, is_paid: true },
    ];
  },
};
```

반환된 데이터는 PG사의 결제 내역과 비교한다. 결제는 완료되었지만 우리 커머스 플랫폼의 '주문 상태가 결제 완료로 처리되지 않은 결제 내역을 식별'하고 필요 시 결제를 취소, 환불 처리하는 데 활용된다.

### 결제 동기화 작업 구현하기 (1)

결제 내역 동기화 작업을 수행하는 로직을 구현한다.

`async function syncPayments() {...}`

1. PG사의 결제 내역(payments) 가져오기
   페이지 단위로 데이터를 요청하여, 결제 데이터가 있는 모든 페이지를 불러와 하나로 합친다.
2. PG사 결제 내역과 일치하는 커머스 플랫폼의 주문 데이터를 조회
3. 누락된 결제 취소 및 환불 처리
   주문 내역과 매칭되지 않은 PG사 결제를 추려내어, 해당 결제 ID(pg_uid)를 취소 API를 통해 처리한다.

```tsx
async function syncPayments() {
  // PG사의 결제 내역(payments) 가져오기
  const payments = fx(range(1, Infinity)) // 언제 끝날지 모르는 작업 목록
    .map(page => [page, page, page]) // 1 => [1, 1, 1] 임시로 최대 3개의 값을 표현
    .take(5) // 5번 만에 끝났다고 가정 (임시)
    .flat() // 2차원 이터레이터를 1차원 이터레이터로 변경
    .toArray(); // 이터러블을 Array로 변환

  console.log(payments);
  // flat() 호출하지 않았다면, [[1, 1, 1], [2, 2, 2], [3, 3, 3], [4, 4, 4], [5, 5, 5]]
  // [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5]
}
```

[PG사 결제 내역을 페이지 단위로 가져오는 작업을 리스트 프로세싱 관점에서 표현한 예제]

- range(1, Infinity) : 언제 끝날지 모를 반복 작업을 무한 이터러블로 표현한다. 이터레이터를 소비할 때마다 1부터 1씩 증가한 값을 제공하며, 각 숫자는 페이지 번호를 나타낸다.
- map(page -> [page, page, page]) : 각 페이지 번호를 받아 [1, 1, 1]과 같은 배열로 변환한다. (실제로는 API 호출 결과를 여기에 매핑할 예정임)
- take(5) : 예제에서는 임의로 5번 만에 작업이 끝난다고 가정했다. (반환된 데이터가 없을 때 중단하도록 로직을 확장할 예정)
- toArray() : 이터러블을 평가하여 2차원 배열 형태로 변환한다. 결과로 페이지 데이터를 담은 배열의 배열이 도출된다.

### 결제 동기화 작업 구현하기 (2)

비동기 핸들링이 가능하도록 toAsync() 활용해 내부에서 사용하는 이터레이터를 AsyncIterator로 변경하고 map의 보조 함수를 PgApi.getPayments로 변경

```tsx
async function syncPayments() {
  const payments = await fx(range(1, Infinity)) // await로 Promise 풀기
    .toAsync() // 비동기 작업으로 변환
    .map(page => PgApi.getPayments(page)) // 결제 내역 가져오기 API 요청

    // .take(5) // 5번 만에 끝났다고 가정 (임시)
    // .takeWhile(({ length }) => length > 0)
    .takeUntilInclusive(({ length }) => length < 3)

    .flat()
    .toArray();

  console.log(payments);
}
```

`.take(5)` <br />
take(5)를 수행할 경우 API를 총 5번 호출하여 3,2,2개의 결제 내역을 받아 하나로 합친다. 4,5번째 요청에서는 데이터가 없는 불필요한 호출이 발생한다. 또한 결제 내역이 15개를 초과하는 경우 누락된다.

이를 개선하기 위해 takeWhile을 활용해 데이터가 존재하는 동안에만 요청을 반복하도록 수정한다. <br />
`.takeWhile(({ length }) => length > 0)` <br />
takeWhile이 조건이 참일 때까지 작업을 소비하며 처음으로 조건이 거짓이 되는 시점까지 작업을 시도한다. 이로 인해 데이터가 없는 페이지에서도 한 번 더 작업이 발생하게 된다.

`.takeUntilInclusive(({ length }) => length < 3)` <br />
처음으로 3보다 적을 때 즉시 멈춤

한 페이지에서 가져오는 최대 결제 내역 개수가 3개이므로 length < 3 조건으로 데이터를 가져온다. 처음으로 조건이 만족되는 순간까지 데이터를 가져오며, 조건 충족시 작업을 즉시 중단한다. 이를 통해 불필요한 데이터 소비를 방지하고 API 호출의 효율성을 높일 수 있다.

### 커머스 플랫폼의 주문 데이터와 매칭, 누락된 결제 취소 및 환불 처리

PG사의 결제 내역과 우리 커머스 플랫폼의 주문 데이터를 비교하여 누락된 데이터를 확인한다.
PG사 결제 내역 (payments)의 각 결제별로 커머스 플랫폼의 주문서 ID를 추출하고, 이를 기반으로 해당 주문 데이터를 조회한다.

```tsx
async function syncPayments() {
  // 1. PG사의 결제 내역(payments) 가져오기
  const payments = await fx(range(1, Infinity))
    .toAsync()
    .map(page => PgApi.getPayments(page))
    .takeUntilInclusive(({ length }) => length < 3)
    .flat()
    .toArray();

  // 2. PG사 결제 내역과 일치하는 커머스 플랫폼의 주문 데이터를 조회

  // 결제가 정상적으로 처리되어 커머스 플랫폼에서 주문 상태가 결제 완료로 표시된 주문 목록이 포함된다.
  const orders = await StoreDB.getOrders(
    // 결제 데이터에서 모든 주문서 ID를 추출
    payments.map(p => p.store_order_id),
    // - payments는 PG사에서 조회한 모든 결제 데이터를 포함하며 각 결제 데이터는 store_order_id를 포함한다.
    // - store_order_id는 커머스 플랫폼의 주문 데이터와 매칭할 수 있는 키로 사용된다.
  ); // 추출한 주문서 ID를 기반으로 커머스 플랫폼의 데이터베이스에서 결제 완료로 처리된 상태의 주문 목록 조회

  // payments와 동일한 수의 orders가 반환되어 모든 결제가 주문 데이터와 1:1로 매칭된다.
  // 만일 orders의 개수가 payments보다 적다면 이는 결제는 성공했지만 커머스 플랫폼에서 주문이 생성되지 않았거나 결제 완료 상태로 갱신되지 않은 경우를 의미한다.
  // 이러한 데이터 불일치가 발견되면 누락된 결제 항목에 대해 결제 취소 및 환불 프로세스를 진행해야 한다.

  // 3. 누락된 결제 취소 및 환불 처리
  // 주문 내역과 매칭되지 않은 PG사 결제를 추려내어, 해당 결제 ID(pg_uid)를 취소 API를 통해 처리한다.
  await fx(payments)
    .toAsync()
    .reject(p => orders.some(order => order.id === p.store_order_id)) // 누락된 것만 남김
    .forEach(async p => {
      const { message } = await PgApi.cancelPayment(p.pg_uid); // 결제 취소 및 환불 진행
      console.log(message);
    });
}
```

reject 함수를 사용하여 payments 데이터 중 orders에 포함되지 않은 항목만 추출한다.
여기서 `orders.some(order => order.id === p.store_order_id)`는 orders 배열을 순회하며 현재 payment의 store_order_id와 일치하는 order가 있는지 확인한다.

조건이 true로 평가된 p는 제거되며 결과적으로 orders는 주문이 누락된 항목만 추려내게된다.

이후 추출된 누락된 결제 데이터를 forEach를 사용해 비동기적으로 모두 소비하며 각 결제 항목에 대해 PaApi.cancelPayment를 호출한다. PgApi.cancelPayment는 결제 취소 및 환불 작업을 수행하는 API로 처리된 결제 항목을 PG사에 전달하여 결제를 취소하고 환불을 진행한다.

## (3) 해시 기반 접근으로 시간 복잡도 최적화

기존 코드는 reject 단계에서 orders.some으로 orders 배열을 순회하며 결제 데이터와 주문 데이터를 매칭했다. <br />
이 접근 방식은 최악의 경우 `O(n * m)`의 시간 복잡도를 가질 수 있다. (n: payments의 길이, m: orders의 길이)

이를 개선하기 위해 **orders를 해시 구조로 변환**하여 특정 order_id의 존재 여부를 `O(1)`로 확인할 수 있도록 최적화했다. 해시 구조를 사용하면 각 store_order_id를 빠르게 조회할 수 있으므로 전체 시간 복잡도를 줄일 수 있다.

```tsx
async function syncPayments() {
  const payments = await fx(range(1, Infinity))
    .toAsync()
    .map(page => PgApi.getPayments(page))
    .takeUntilInclusive(({ length }) => length < 3)
    .flat()
    .toArray();

  const orders = await StoreDB.getOrders(payments.map(p => p.store_order_id));

  // 키-값 배열을 객체로 변환하여 해시 구조 생성
  const ordersMapById = new Map(
    // orders 배열을 키-값 배열 형태로 변환
    map(order => [order.id, true], orders),
  );
  // { 1： true, 3： true, 5： true, 7： true, 8： true }

  await fx(payments)
    .toAsync()
    .reject(p => ordersMapById.has(p.store_order_id)) // O(1)로 매칭된 결제 내역 제거
    .forEach(async p => {
      const { message } = await PgApi.cancelPayment(p.pg_uid);
      console.log(message);
    });
}
```

기존에는 orders.some으로 배열을 순회하며 조건을 확인했지만 이제는 해시 구조를 사용하여 `ordersById[p.store_order_id]`로 매칭 여부를 빠르게 확인한다.

선호도에 따라 Map과 같은 내장 객체를 만들어서 활용해도 좋다. 대규모 데이터셋의 경우 일반 Array의 map보다 이터레이터를 활용한 map이 메모리 효율 면에서 유리하다.
Map의 생성자는 배열뿐 아니라 이터러블도 받을 수 있어 지연된 결과를 전달해 값 복사를 최소화할 수 있다. 추가로 대규모 데이터셋일수록 일반적으로 Object보다 Map을 사용하는 것이 성능 면에서 더 효율적이다.

리스트 프로세싱에 익숙해지면 데이터 구조 변형이 쉬워지고 이와 같은 최적화를 쉽게 구현할 수 있다. 이러한 최적화는 대규모 데이터셋에서도 효율적인 처리를 가능하게 하며 데이터의 구조와 요구사항에 따라 적합한 방식으로 로직을 설계하는 데 큰 도움이 된다.

## (4) 안정적인 비동기 작업 간격 유지

syncPayments를 일정한 시간 간격으로 반복 실행하도록 구현한다.

```tsx
async function runScheduler() {
  // range(Infinity)를 활용한 무한 이터러블 - 언제 끝날지 모르는 반복 작업을 위함
  await fx(range(Infinity))
    .toAsync() // 위의 반복 작업은 toAsync를 통해 비동기적으로 전환된다.
    // forEach를 활용하여 이터러블의 각 항목을 순회하며 작업을 실행한다.
    .forEach(() =>
      // Promise.all을 사용해 비동기 작업을 그룹화하고 병렬로 처리한다.
      Promise.all([
        // syncPayments()는 결제 데이터 동기화를 수행하며 이 작업이 완료되는 데 걸리는 시간은 가변적이다
        syncPayments(),
        // 10초를 기다리게 하는 코드이며, Promise.all은 두 작업이 모두 완료될 때까지 대기한다.
        delay(10000),
      ]),
    );
}
```

syncPayments가 10초보다 오래 걸리면 delay(10000)이 이미 완료되어 syncPayments의 실행 시간이 작업 간격을 결정한다. 반대로 syncPayments가 10초보다 적게 걸리면 delay(10000)으로 인해 충분히 대기한 후에 반복 작업이 실행된다. 이 동작은 외부 API 호출 등의 부하를 조절하고 작업 간 간격을 안정적으로 유지하도록 보장한다.

이러한 기법은 외부 API 호출 빈도를 조절하거 나 제공된 요청 제한 정책을 준수하는 데 매우 유용하다. 리스트 프로세싱은 데이터 동기화, 크롤러, API 호출 등과 같은 백엔드 작업에서도 안정성과 효율성, 유지보수성, 가독성을 보장한다.

특히 이 예제에서는 Promise.all을 효과적으로 활용했다. Promise.all을 통해 작업 간 상호 독립성을 유지하며 병렬로 실행할 수 있다. 또한 Promise.all은 복잡한 비동기 로직을 간단하고 명확하게 표현해 문제 해결 과정을 훨씬 직관적으로 만든다.
Promise.all의 완료 로직과 Promise.race의 완료 로직은 마치 Math.max와 Math.min의 결과를 받는 것처럼 직관적이다. 이러한 선언적 접근 방식은 복잡한 비동기 작업을 효과적으로 관리하고 코드를 간결하면서도 이해하기 쉽게 만든다.

## (5) 최대 요청 크기 제한을 효과적으로 처리하기

현대 백엔드 시스템은 외부 API, 데이터베이스 또는 마이크로서비스 간의 통신에서 특정 요청 크기에 제한을 두는 경우가 많다. 이러한 제한은 안정적인 서비스 운영을 위한 필수 조건이지만 이를 제대로 처리하지 못하면 서비스 중단이나 예기치 않은 에러로 이어질 수 있습니다.

한 번에 처리할 수 있는 요청 크기를 5개로 제간 조건을 시뮬레이션하고 리스트 프로세싱을 활용해 문제를 해결하는 방법을 나타내면 다음과 같다.

```typescript
type Order = {
  id: number;
  amount: number;
  is_paid: boolean;
};

const StoreDB = {
  async getOrders(ids: number[]): Promise<Order[]> {
    if (ids.length > 5) {
      throw new Error(
        `ID 개수 초과: 최대 5개까지 요청할 수 있습니다. (전달된 개수: ${ids.length})`,
      );
    }
    console.log(`SELECT * FROM orders WHERE IN (${ids}) AND is_paid = true;`);
    await delay(100);
    return [
      { id: 1, amount: 15000, is_paid: true },
      { id: 3, amount: 10000, is_paid: true },
      { id: 5, amount: 45000, is_paid: true },
      { id: 7, amount: 20000, is_paid: true },
      { id: 8, amount: 30000, is_paid: true },
    ];
  },
};
```

chunk를 활용해 요청을 5개씩 분할하여 안전하고 효율적으로 데이터를 조회합니다.

```typescript
async function syncPayments() {
  // ...

  const orders = await fx(payments)
    .map(p => p.store_order_id) // map 함수로 각 payment 객체에서 store_order_id를 추출하여 쿼리 요청에 필요한 ID 배열을 생성한다.
    .chunk(5) // ID 배열을 5개씩 묶어 요청 제한을 충족하도록 분할한다.
    .toAsync() // 동기 이터러블을 비동기 이터러블로 변환한다. -> 이를 통해 비동기 작업을 리스트 프로세싱으로 처리할 수 있다.
    .flatMap(
      StoreDB.getOrders, // 분할된 ID 그룹을 StoreDB.getOrders로 전달하여 처리한다.
      // 이후 각 그룹의 결과를 평탄화하여 최종 결과를 하나의 배열로 병합한다.
    )
    .toArray(); // 처리된 모든 결과는 하나의 배열로 반환한다.
}
```

이 코드는 ID의 개수 제한을 준수하면서도 데이터를 효율적으로 조회할 수 있도록 설계되었습니다. 요청은 항상 5개 이하로 나뉘며 제한된 개수를 초과하는 요청은 발생하지 않습니다. 결과적으로 예상치 못한 에러를 방지하고 안정적으로 데이터를 조회할 수 있습니다.

## (6) 사전 카운트로 효율 높이기

페이지 수를 사전에 확인할 수 있는 기능을 제공하면 효율성을 크게 향상시킬 수 있습니다. 데이터를 먼저 요청한 뒤 takeWhile이나 takeUntillnclusive로 확인하는 방식 대신 필요한 요청 횟수를 미리 예측하여 정확하고 효율적으로 처리할 수 있습니다. 또한 총 페이지 수를 확인하는 작업은 결제 내역을 실제로 조회하는 것보다 **훨씬 가벼운 데이터베이스 작업이므로 시스템 자원을 더욱 효율적으로 사용할 수 있습니다**.

나아가 결제 내역의 요청의 필요성을 사전에 판단하여 요청 자체를 생략할 수 있어 불필요한 작업을 방지할 수도 있습니다.

[예제] 결제 데이터를 실제로 조회하기 전에 총 페이지 수를 미리 확인하는 API 추가한 예제

```typescript
// Payment Gateway API
const PgApi = {
  /**
   * 특정 시간 동안의 총 페이지 수 반환 (편의상 시간 범위를 지정하는 인자는 생략)
   * @returns 총 페이지 수
   */
  async getPageCount() {
    console.log('Page count request: https://pg.com/payments/page-count');
    await delay(50); // 데이터베이스에서 간단한 카운트 작업을 시뮬레이션
    return pgDataPaymentsPages.length; // 결제 내역이 저장된 총 페이지 수 반환
  },

  /**
   * 특정 시간 동안의 모든 결제 내역 조회 (편의상 시간 범위를 지정하는 인자는 생략)
   * @param page 조회할 페이지 번호
   */
  async getPayments(page: number) {
    console.log(`Payments request: https://pg.com/payments?page=${page}`);
    await delay(500); // 변경해보세요.

    const payments = pgDataPaymentsPages[page - 1] ?? [];
    console.log(
      `${payments.length}개: ${payments.map(p => p.pg_uid).join(', ') || '-'}`,
    );

    return payments;
  },
  // ... 생략
};
```

getPageCount를 사용하면 getPayments 요청 횟수를 정확히 설정할 수 있어 불필요한 호출을 방지할 수 있습니다. 페이지 카운트는 결제 데이터 전체를 조회하지 않고도 총량을 파악하므로 상대적으로 가벼운 데이터베이스 작업으로 비용을 절감할 수 있습니다.

```tsx
const totalPages = await PgApi.getPageCount(); // 3

// const payments = await fx(range(1, Infinity))
//   .toAsync()
//   .map(page => PgApi.getPayments(page))
//   .takeUntilInclusive(({ length }) => length < 3) // 결과를 확인하며 중단하는 추가 조건 불필요
//   .flat()
//   .toArray();

// 무한 이터레이터 대신 필요한 만큼만 결제 데이터를 요청하도록 변경
const payments = await fx(range(1, totalPages + 1)) // 정확한 요청 횟수를 보장
  .toAsync()
  .map(page => PgApi.getPayments(page))
  .flat()
  .toArray();
```

- totalPages가 2인 경우 range(1, 3)이 생성됩니다. 이는 페이지 1과 2를 요청하도록 하며 정확히 두 번의 PgApi.getPayments 호출이 이루어집니다.
- totalPages가 0인 경우 range(1, 1)이 생성되어 빈 이터레이터가 만들어집니다. 이 경우 이터레이터를 소비하더라도 PgApi.getPayments는 한 번도 호출되지 않으며 결과적으로 payments는 빈 배열이 됩니다. 이렇게 데이터 요청이 전혀 이루어지지 않는 효율적인 동작을 보장합니다.

## (7) 병렬성으로 효율 높이기

총 몇 페이지를 요청해야 하는지 알면 모든 페이지를 반드시 순차적으로 요청할 필요가 없습니다. 병렬 처리를 활용하여 요청 시간을 단축할 수 있습니다.

### concurrent 메서드 사용법

순차적으로 비동기 이터레이터를 소비하는 코드

```tsx
await fx([1, 2, 3, 4, 5, 6])
  .toAsync()
  .map(a => delay(1000, a))
  .concurrent(2)
  .toArray();

// 3 seconds

// [1][2][3][4][5][6]
// (1)(1)(2)(2)(3)(3)

await fx([1, 2, 3, 4, 5, 6])
  .toAsync()
  .map(a => delay(1000, a))
  .concurrent(4)
  .toArray();

// 2 seconds

// [1][2][3][4][5][6]
// (1)(1)(1)(1)(2)(2)
```

concurrent 메서드를 추가하여 코드를 병렬로 실행할 수 있습니다. concurrent를 실행하면 인자로 전달받은 수만큼 동시에 이터 레이터를 소비합니다.

총 몇 페이지를 요청해야 하는지 사전에 알 수 있습니다. 따라서 concurrent를 활용하여 기존 syncPayments를 간단히 수정함으로써 병렬성을 적용하여 효율을 높일 수 있습니다.

```tsx
async function syncPayments() {
  // 1. PG 사의 결제 내역(payments) 가져오기
  const totalPages = await PgApi.getPageCount(); // 3
  // (50ms 소요)

  // totalPages 개수만큼 동시에 병렬로 요청
  const payments = await fx(range(1, totalPages + 1))
    .toAsync()
    .map(page => PgApi.getPayments(page))
    .concurrent(totalPages) // totalPages 개수만큼 동시에 병렬로 요청
    .flat()
    .toArray();
  // 총 3번의 getPayments를 모두 동시에 요청
  // (500ms 정도 소요)
}
```

concurrent(totalPage)를 사용하여 결제 데이터 요청을 병렬로 처리합니다.
totalPages 값만큼의 페이지를 동시에 요청하므로 순차 처리보다 요청 시간이 대폭 단축됩니다.
이전 코드에서는 3번 순차적 수행하여 총 1500ms 소요되었으나, 이제는 페이지 수 조회 50ms + getPayments 3회 병령 실행으로 500ms = 총 550ms 정도가 소요됩니다.

순차 처리에서는 각 페이지 데이터를 순서대로 요청하고 대기해야 하므로 응답 시간의 합이 전체 작업 시간에 직접적인 영향을 미칩니다. 병렬 처리는 모든 페이지를 동시에 요청하므로 작업 시간은 가장 오래 걸리는 요청의 응답 시간으로 제한됩니다. 병렬 처리로 작업 속도를 크게 향상시킬 수 있으며, 네트워크 대기 시간을 최소화하고 시스템 리소스를 효과적으로 활용할 수 있습니다.

추가로 병렬 요청이 가능한지 여부는 대상 API의 제한(예: 요청 제한)에 따라 달라질 수 있습니다. 만일 요청 제한에 의해 동시에 최대 2개의 요청 정도로 제한해야 한다면 concurrent(2)를 전달하여 다음과 같이 동작하도록 설정할 수 있습니다.

```tsx
async function syncPayments() {
    const totalPages = await PgApi.getPageCount(); // 3

    const RATE_LIMIT = 2;

    const payments = await fx(range(1, totalPages + 1))
      .toAsync()
      .map(page => PgApi.getPayments(page))
      .concurrent(RATE_LIMIT)
      .flat()
      .toArray();

    const orders = await fx(payments)
      .map(p => p.store_order_id)
      .chunk(5)
      .toAsync()
      .flatMap(StoreDB.getOrders)
      .toArray();

    // [5-39]
    const ordersMapById = new Map(map(order => [order.id, true], orders));

    await fx(payments)
      .toAsync()
      .reject(p => ordersMapById.has(p.store_order_id))
      .forEach(async p => {
        const { message } = await PgApi.cancelPayment(p.pg_uid);
        console.log(message);
      });
  }

  async function runScheduler() {
    await fx(range(Infinity))
      .toAsync()
      .forEach(() => Promise.all([syncPayments(), delay(10000)]));
  }

  await runScheduler();
}
```

## (8) 리스트 프로세싱 기반 비동기/동시성 프로그래밍

지금까지 백엔드 프로그래밍에서 자주 직면하는 문제를 해결하기 위한 리스트 프로세싱의 여러 접근 방식을 살펴보았습니다.

먼저 데이터 불일치와 같은 실질적인 문제를 해결하기 위해 **결제 내역 동기화 스케줄러를 구현**하는 과정을 배웠습니다. 이를 통해 효율적이고 신뢰할 수 있는 데이터 동기화 방법을 탐구했습니다.

또한 **해시 기반 접근을 사용하여 시간 복잡도를 최적화**하는 방법을 다루었으며 데이터 매칭 작업에서 효율성을 높이는 기법을 소개했습니다. 이를 통해 대규모 데이터셋에서도 성능을 보장할 수 있는 설계 방식을 알아봤습니다.

**안정적인 비동기 작업 간격 유지**를 통해 외부 API 호출과 같은 작업에서 작업 간의 간격을 안정적으로 유지하며 시스템 부하를 관리하는 방법을 익혔습니다. 이를 통해 비동기 로직을 직관적으로 관리하고 선언적으로 표현하는 중요성을 강조했습니다.

**최대 요청 크기 제한**을 효과적으로 처리하는 방법은 실무에서 자주 발생하는 요청 제한 문제를 안전하게 해결하는 기법입니다. 리스트 프로세싱을 활용해 요청 크기를 조정하며 효율성을 높이는 접근 방법으로 실전적인 도구로서의 가치를 강조했습니다.

이어서 **사전 카운트** API를 사용해 전체 페이지 수를 미리 파악하고 이를 기반으로 불필요한 요청을 줄이며 효율성을 극대화할 수 있는 설계를 논의했습니다. 마지막으로 **병렬 요청**을 활용해 대기 시간을 줄이고 작업 속도를 최적화하는 방법을 살펴보았습니다.

리스트 프로세싱으로 해결하는 방식은 **성능과 로직을 효율적으로 만드**는 데 그치지 않고 **복잡한 문제를 선언적이고 구조적으로 접근할 수 있는 강력한 도구를 제공**합니다. 이러한 접근 방식은 가독성 높은 코드 작성과 유지보수성 향상, 시스템 자원 최적화, 개발 생산성 등 다방면에서 실질적인 이점을 가져옵니다. 데이터 흐름을 선언적으로 제어하면서 비동기 처리와 병렬성 같은 복잡한 문제를 자연스럽게 해결할 수 있다는 점에서 리스트 프로세싱은 단순한 프로그래밍 기법을 넘어 생산성과 안정성을 동시에 실현할 수 있는 핵심적
인 접근 방식입니다.
